---
title: "Emory Covid-19 Case Study Script"
author: "EpiRHandbook Team"
date: "13 August 2021"
output: 
  officedown::rdocx_document: 
            reference_docx: "template_style.docx"
            keep_md: TRUE
params: 
     surveillance_date: 2021-06-30
---


# Introduction to this case study script

This is a an example R-markdown script which demonstrates how to create an 
automated outbreak situation report for COVID-19 in Fulton county, USA.  

- We demonstrate how to import, clean and analyse your data.  
- Analysis is organised by time, place and person.  
     - For the purpose of the case study we separate this by descriptive analysis
     and visualisation (normally this would be mixed together of course)  
     - Analysis is loosely based off the monthly [epidemiology reports](https://www.fultoncountyga.gov/covid-19/epidemiology-reports) 
     for Fulton county  
- Text within <! > will not show in your final document.  
     - The other parts such as slashes (///), dashes (-) and tildes (~) are just aesthetic
     - These comments are used to explain the code chunks.   
     - We refer to functions in curly brackets, e.g. {dplyr} and functions end in brackets, e.g. count()  
     - This comment will not show up when you knit the document.  
     - You can delete them if you want.  
- Feedback & suggestions are welcome at the [GitHub issues page](https://github.com/appliedepi/emory_training/issues)  
     - Alternatively email us at: [epirhandbook@gmail.com](mailto:epiRhandbook@gmail.com)  


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
This comment will not show up when you knit the document.
A comment with a title with slashes indicates a name of a code chunk.
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// setup \\\
--------------------------------------------------------------------------------

Several packages are required for different aspects of  analysis with *R*. 
You will need to install these before starting. 

We install and load packages using the {pacman} package. 

This might prove difficult if you have limited administrative rights for your 
computer. Making sure your IT-department gives you the correct access can save a 
lot of headache. 

See this handbook pages on the basics of installing packages and running R from 
network drives (company computers) for more detail. 

https://epirhandbook.com/r-basics.html#installation
https://epirhandbook.com/r-on-network-drives.html#r-on-network-drives
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r setup, include=FALSE}

#TODO: turn off warnings and messages 

# hide all code chunks in the output, but show errors 
     # nb. warnings and messages still shown
knitr::opts_chunk$set(echo = FALSE,  # hide all code chunks in output
                      error = TRUE,  # show errors if they appear, but don't stop (produce the word doc)
                      fig.topcaption = TRUE  # show figure titles on top of plot
                     )

# Ensures the package "pacman" is installed
if (!require("pacman")) {
     install.packages("pacman") }

# install (if necessary) and load packages to be used
pacman::p_load(
  officedown, # format MS word document output
  officer,    # add table of contents to output
  rio,        # importing data  
  here,       # relative file pathways 
  skimr,      # get overview of data
  janitor,    # data cleaning and tables
  lubridate,  # working with dates
  epikit,     # age_categories() function
  tidyverse,  # data management and visualization
  flextable,  # converting tables to pretty images
  sf,         # manage spatial data using a Simple Feature format
  scales      # define colour schemes for flextables 
)

```


\pagebreak 
<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// table_of_contents \\\
--------------------------------------------------------------------------------
This chunk adds a table of contents to your report using the {officedown} package. 
You can also add in a list of tables and figures. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r table_of_contents}

# table of contents based on headings 
block_toc() 

# list of tables 
block_toc(style = "Table Caption")

# list of figures 
block_toc(style = "Image Caption")

```

\pagebreak 


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// define_reporting_periods \\\
--------------------------------------------------------------------------------
Here we use the date you want to report on, defined in parameters above to create
a date object which we can use for filtering datasets and analysis. 

We also create a week object to make grouping data easier. In this scenario we 
have defined the week to start on Wednesdays as this is when Fulton County 
releases their reports (but you can choose any other day of the week too). 

From these we are then able to define periods 14 and 28 days prior to our 
situation report date. We can also make the appropriate labels to auto-populate
table titles. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r define_reporting_periods}

# create a date object from the parameter
# Minus 7 days surveillance date to account for lag in reporting lab results
surveillance_date <- as.Date(params$surveillance_date) - 7

# create an epiweek object from the date 
# floor_date rounds to the closest week here
surveillance_week <- floor_date(surveillance_date,
                          # round by weeks
                          unit = "week", 
                          # define week to start on Wednesday
                          week_start = 3)

# define recent (past 14 days) and previous (28 to 14 days prior)
recent_period   <- c(seq(surveillance_week  - 13, surveillance_week, by = 1))
previous_period <- c(seq(surveillance_week  - 27, surveillance_week - 14, by = 1))

# define the cut-off dates for the recent period (for table headers)
recent_period_labels <- str_c(
  format(min(recent_period), format = "%m/%d"), 
  "-", 
  format(max(recent_period), format = "%m/%d")
)

# define the cut-off dates for previous period (for table headers) 
previous_period_labels <- str_c(
  format(min(previous_period), format = "%m/%d"), 
  "-", 
  format(max(previous_period), format = "%m/%d")
)


# define a label for past 28 days (for table captions)
full_period_labels <- str_c(
  format(min(previous_period), format = "%B %d"), 
  "-", 
  format(surveillance_week, format = "%B %d, %Y")
)


```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// import \\\
--------------------------------------------------------------------------------

We use the {rio} package for importing our example data - it is very versatile 
and can read in most file types. 

We use the {here} package for defining the path to our file. This is important 
for sharing your script with others (by email or on Sharepoint) - if you used an
"absolute" path, they would need to update the script to match their computer. 

This way your whole R-project folder can be zipped up and moved somewhere else. 

For more details see: 
https://epirhandbook.com/import-and-export.html
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r import}

## TODO: at the end remove "case_study" from path - so that can be used within case_study.Rproj (also delete the if statement [keep the else])

if (str_detect(here::here(), "emory_training")) {

linelist_raw <- here::here("case_study", "data",
                     "covid_example_data", "covid_example_data.xlsx") %>%
     # specify the sheet to read using which (default is to read first sheet)
     import(which = "in")

shapefile <- read_sf(here::here("case_study", "data",
                     "covid_example_data", "covid_shapefile", "FultonCountyZipCodes.shp"))
} else {
  
# import the raw case data set 
  # define the path using {here} then pass that to the {rio} import function
linelist_raw <- here("data",
                     "covid_example_data", "covid_example_data.xlsx") %>%
     # specify the sheet to read using which (default is to read first sheet)
     import(which = "in")

# import shapefile
  # for mapping and for extracting population counts for zipcodes
shapefile <- read_sf(here("data", 
                     "covid_example_data", "covid_shapefile", "FultonCountyZipCodes.shp"))
}

```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// browse_data \\\
--------------------------------------------------------------------------------

Here we take a look at the raw data to get a feel for what needs cleaning. 

We first use the in-built browser with the {base} function View(). 

Then we can use the {base} function summary(), but probably the most comprehensive 
overview is with the {skimr} function. 
You can also view distinct values for variables using the {base} unique() function. 

For more details see: 
https://epirhandbook.com/cleaning-data-and-core-functions.html#review
https://epirhandbook.com/descriptive-tables.html#browse-data
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r browse_data, eval = FALSE}

# view your whole dataset interactively (in an excel style format)
View(linelist_raw)

# get summary: 
# mean, median and max values of numeric variables
# counts for categorical variables
# also gives number of NAs
summary(linelist_raw)

# get information about each variable in a dataset 
     # nb. “POSIXct” is a type of raw date class 
skim(linelist_raw)

# view unique values contained in variables 
# you can run this for any column -- just replace the column name
unique(linelist_raw$case_gender) 

```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// clean_colnames \\\
--------------------------------------------------------------------------------

Here we are going to clean the column names of our data set - and store as a new
dataset called "linelist". 

It is possible to use the {janitor} package for automated cleaning of variable 
names - but as there are only a few variables that we want to rename, 
here we will demonstrate using {dplyr} select() function for manually renaming.

Select() can be used either to retain specific columns or to rename them by using
the syntax New name = Old name. 

For more details see: 
https://epirhandbook.com/cleaning-data-and-core-functions.html#column-names
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r clean_colnames}

# create a new object called linelist and assign linelist_raw with renamed columns
linelist <- linelist_raw %>% 
  # use select() to retain columns and rename them 
     # NEW name = OLD name
     # aligned for readability
  select( 
    pid                 = PID,
    date_report         = reprt_creationdt_FALSE,      
    date_dob            = case_dob_FALSE,              
    age                 = case_age,                    
    gender              = case_gender,
    race                = case_race,
    eth                 = case_eth,
    zip                 = case_zip,
    county              = case_county,
    district            = case_district,
    state               = case_state,
    contact_id          = Contact_id, 
    date_onset          = sym_startdt_FALSE,
    sym_fever,
    sym_subjfever,
    sym_myalgia,
    sym_losstastesmell,
    sym_sorethroat,
    sym_cough,
    sym_headache,
    sym_resolved,
    date_recovery       = sym_resolveddt_FALSE, 
    contact_hh          = contact_household,
    hospitalized,  
    date_hospitalized   = hosp_admidt_FALSE,
    date_discharge      = hosp_dischdt_FALSE,
    died,  
    died_covid,  
    date_died           = died_dt_FALSE,
    confirmed_case, 
    covid_dx, 
    date_positive       = pos_sampledt_FALSE,
    lat                 = latitude_JITT,
    lon                 = longitude_JITT
    )

```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// clean_dates \\\
--------------------------------------------------------------------------------

Here we are going to clean the date variables 

It is possible to use the {janitor} package for automated cleaning of variable 
names - but as there are only a few variables that we want to rename, 
here we will demonstrate using {dplyr} select() function for manually renaming.

Select() can be used either to retain specific columns or to rename them by using
the syntax New name = Old name. 

For more details see: 
https://epirhandbook.com/cleaning-data-and-core-functions.html#column-names
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r clean_dates}

linelist <- linelist %>%
     
  # convert all date columns, ymd() from lubridate
  mutate(across(contains("date"), ymd)) %>%

  # remove onset dates prior to 2020
  mutate(
       across(
    .cols = c(date_report, date_onset, date_hospitalized, date_discharge, date_died),
    .fns  = ~replace(.x, .x < as.Date("2020-01-01"), NA)
    )) %>% 

  # remove dates after the surveillance_date (for this report) from all date columns
  mutate(across(
    .cols = contains("date"),
    .fns  =  ~replace(.x, .x > surveillance_date, NA)
    )) %>%
     
  # create an epiweek object from the report date 
  # floor_date rounds to the closest week here
  mutate(epiweek = floor_date(date_report,
                          # round by weeks
                          unit = "week", 
                          # define week to start on Wednesday
                          week_start = 3)
  )

```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// clean_numerics \\\
--------------------------------------------------------------------------------

Here we are going to clean all numeric variables, as well as create some new 
variables based on difference between dates. 

First we will ensure that age is numeric and then fix those with incorrectly 
entered dates (notice that one individual was -20 years old). 

Then we show how to create new numeric variables for the number of days between 
two dates. 

For more details see: 
https://epirhandbook.com/cleaning-data-and-core-functions.html#num_cats
https://epirhandbook.com/cleaning-data-and-core-functions.html#clean_case_when
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r clean_numerics}

# Age 
############

linelist <- linelist %>%
  mutate(
    # ensure that age is a numeric variable
    age = as.numeric(age),
    # set those with negative ages and missing DOB to missing 
    # otherwise just leave the age value as is
          # nb. NA_real_ just ensures the variable class is not changed
    age = if_else(age < 0 & is.na(date_dob), NA_real_, age)
  )

     
# Calculating time differences 
##############################

linelist <- linelist %>%
     
  # delay from onset to hospitalization
  mutate(
    # calculate time differences
    days_onset_hosp = as.numeric(date_hospitalized - date_onset),
    # set those under 0 or over 30 to missing
    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp < 0, NA),
    days_onset_hosp = replace(days_onset_hosp, days_onset_hosp > 30, NA)
  ) %>%
     
  # length of hospitalization
  mutate(
    # create outcome date based on whether died or was discharged first
    date_outcome = coalesce(date_died, date_discharge),
    # calculate time difference
    days_hosp = as.numeric(date_outcome - date_hospitalized),
    # set those under 0 or over 60 to missing
    days_hosp = replace(days_hosp, days_hosp < 0, NA),
    days_hosp = replace(days_hosp, days_hosp > 60, NA)
  )

```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// clean_categories \\\
--------------------------------------------------------------------------------

create age groups based on the age variable using 
the age_categories() function from {epikit}. It is also possible to create 
age groups using the {dplyr} case_when() function - but is more involved. 

For more details see: 
https://epirhandbook.com/cleaning-data-and-core-functions.html#column-creation-and-transformation
https://epirhandbook.com/cleaning-data-and-core-functions.html#re-code-values
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r clean_categories}

linelist <- linelist %>% 
     
     # create age group variable
     mutate(
     age_group = age_categories(age,
      # define break points
      c(0, 10, 20, 30, 40, 50, 60, 70),
      # whether last break should be highest category
      ceiling = FALSE
     )) %>% 
     
     # replace one category and leave the rest as they are 
     mutate(died_covid = if_else(died_covid == "Under Review", 
                                 "Unknown", died_covid), 
            confirmed_case = if_else(confirmed_case == "Pending", 
                                     "Unknown", confirmed_case), 
            sym_myalgia = if_else(sym_myalgia == "YES", "Yes", sym_myalgia)
            ) %>% 
     
     #replace one category and leave rest over multiple variables 
     mutate(across(c(contact_hh, contains("sym_")),
                   ~if_else(.x == "Unk", "Unknown", .x) 
                   )) %>% 

     # create a composite category from race and ethnicitiy  
          #  (nb. this sets those that are non-specified in eth to non-hispanic)
     mutate(eth_race = case_when(
          eth == "HISPANIC/LATINO"                            ~ "Hispanic, all races", 
          race == "ASIAN" & 
               eth != "HISPANIC/LATINO"                       ~ "Asian, NH", 
          race == "BLACK" & 
               eth != "HISPANIC/LATINO"                       ~ "Black, NH",
          race == "WHITE" & 
               eth != "HISPANIC/LATINO"                       ~ "White, NH",
          race == "AMERICAN INDIAN/ALASKA NATIVE" |
               race == "NATIVE HAWAIIAN/PACIFIC ISLANDER" |
               race == "OTHER" & 
               eth != "HISPANIC/LATINO"                       ~ "Other, NH", 
          TRUE                                                ~ "Unknown"
     )) %>% 
     
     # change from upper-case to lower case (with leading capital)
     mutate(across(c(county, state), str_to_title)) %>% 
     
     # remove text from a string (everything after the dash)  
     mutate(contact_id = str_remove(linelist$contact_id, "-.*")) %>% 
     
     # recode with searching for string patterns 
     mutate(sym_resolved = case_when(
          str_detect(sym_resolved, "Yes")     ~ "Yes", 
          str_detect(sym_resolved, "No")      ~ "No", 
          str_detect(sym_resolved, "Unknown") ~ "Unknown", 
          TRUE                                ~ "Unknown"
     )) %>% 
     
     
     # create a factor 
     mutate(zip = as_factor(zip)) %>% 
     
  
     # replace missing with "Unknown" where relevant 
     mutate(across(.cols = c(gender, race, eth, zip, 
                             county, contact_id, contact_hh, 
                             hospitalized, died, died_covid, confirmed_case,
                             contains("sym_"), age_group),
          ~fct_explicit_na(.x, na_level = "Unknown"))) %>% 
    
     # set levels of a factor (define order)
     mutate(gender      = fct_relevel(gender, "Female", "Male", "Unknown"), 
            eth_race    = fct_relevel(eth_race, 
                                   "Asian, NH", "Black, NH", "White, NH", 
                                   "Hispanic, all races", "Other, NH", "Unknown")
         ) %>% 
     
     # set levels of all factors that are yes/no/unknown 
     mutate(across(
          c(contact_id, contact_hh, hospitalized, died, died_covid, confirmed_case, 
            contains("sym_")), 
          ~fct_relevel(.x, "Yes", "No", "Unknown")
          ))
```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// vector_vars \\\
--------------------------------------------------------------------------------

Here we are going to store a list of variable names that we can then use for 
iterating later on rather than typing them out each time. 
In this example we are going to take all the symptom variables and store them in 
a vector. 
It is also possible to simply type these out with quotation marks within a c(...)
argument. 

For more details see: 
https://epirhandbook.com/iteration-loops-and-lists.html
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r vector_vars}

# define a list of variables for looping over later
symptom_vars <- linelist %>% 
     # choose all columns that contain "sym_" in the name but exclude "sym_resolved"
     select(c(contains("sym_"), -sym_resolved)) %>% 
     # pull the names out 
     names()

# type out the variables of interest
demographic_vars <- c("gender", "age_group", "eth_race")

```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// duplicated \\\
--------------------------------------------------------------------------------

Here we remove the duplicates based on having the same pid, gender and date of 
birth. 
Note that this might exclude those which are legitimately reported twice - i.e. 
those who recovered and were reinfected. To deal with these you could create a 
composite variable of the identifiers of interest, flag the duplicates there and 
then add an additional argument for having a report date within six months. 

For more details see: 
https://epirhandbook.com/de-duplication.html 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r duplicated}

# get a list of all the duplicates 
     # this is mostly to inspect manually but can be used for analysing those dropped
duplicates <- linelist %>% 
     get_dupes(pid, gender, date_dob)

linelist <- linelist %>% 
  ## find duplicates based on unique ID, gender and date of birth and age group 
  ## only keep the first occurrence 
  distinct(pid, gender, date_dob, .keep_all = TRUE)

```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// filter \\\
--------------------------------------------------------------------------------

Here we are going to filter our data set to only keep relevant cases for analysis. 
We keep those that are reported before our surveillance cut-off date and those 
that are entered as a confirmed case. 

For more details see: 
https://epirhandbook.com/cleaning-data-and-core-functions.html#filter-rows
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r filter}

# get those which do not meat our filter criteria 
dropped <- linelist %>% 
     filter(confirmed_case != "Yes" | 
                 date_report > surveillance_date & 
                 !is.na(date_report))


# drop the cases that dont meet the criteria 
linelist <- linelist %>% 
     filter(confirmed_case == "Yes" & 
              date_report <= surveillance_date & 
                 !is.na(date_report))
```

\pagebreak

# Descriptive analysis 
This section will be analysing data by time place and person to produce descriptive
tables. 

## Summary 
TODO: add in the summary bullet points as seen in the Fulton report

## Time 

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// epiweek_table \\\
--------------------------------------------------------------------------------

Here we use the {janitor} tabyl() function to get case counts by calendar week 
(as well as the percentage these contribute to the overall). 

We then create use {flextable} to produce a clean output table. 

For more details see: 
https://epirhandbook.com/descriptive-tables.html
https://epirhandbook.com/tables-for-presentation.html
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r epiweek_table, tab.cap="COVID-19 case counts by calendar week in Fulton County", tab.id="time_tab"}

## TODO: comment all code from here on

linelist %>% 
  # get counts and percentages 
  tabyl(epiweek) %>% 
  # add the overall counts as a row
  adorn_totals() %>%  
  # change from proportions to percentages (do not add a % sign)
  adorn_pct_formatting(affix_sign = FALSE) %>% 
  # rename columns 
  select("Calendar Week" = epiweek, 
         "Cases (n)" = n, 
         "Percent (%)" = percent) %>% 
  # produce styled output table
  flextable() %>% 
  # fit columns widths to contents
  autofit()

```

As you can see from above in TODO fix this reference... table \@ref(tab:time_tab) we saw xyz (TODO: say something meaningful)

\pagebreak 

## Place 

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// zip_counts \\\
--------------------------------------------------------------------------------

Here we use {dplyr} functions to get case counts based on periods created in the 
define_reporting_periods code chunk above. 
We store as an object called zip_counts so that it can be merged with population
in the chunks below. 

For more details see: 
https://epirhandbook.com/descriptive-tables.html#dplyr-package
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r zip_counts}

zip_counts <- linelist %>% 
  group_by(zip) %>% 
  # count cases in the appropriate period 
  summarise(
    recent   = sum(date_report %in% recent_period),
    previous = sum(date_report %in% previous_period)
  ) %>% 
  adorn_totals() %>% 
  # a percentage change column and round the digits
  mutate(
    perc_change = round((recent - previous) / previous * 100, digits = 1), 
    )

```

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// zip_join \\\
--------------------------------------------------------------------------------

Here we use {dplyr} functions extract the population counts from our shapefile, 
and then merge these with our zip_counts from above. 
N.b. the left_join functions preserves all the rows from the first dataset 
provided and only merges the rows from the second that match. 
We then calculate incidence per 10,000 population. 

For more details see: 
https://epirhandbook.com/descriptive-tables.html#dplyr-package
https://epirhandbook.com/joining-data.html
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r zip_join}

# extract population counts for each zip from the shapefile
zip_pop <- shapefile %>% 
  # change to tibble (otherwise geo-data gets pulled with)
  as_tibble() %>% 
  # only keep zip code and population counts
  select(ZipCode, Population) %>% 
  # add a row with overall counts
  adorn_totals()
  
# merge case counts and population counts
# zip (or ZipCode in the shapefile) variable is the unique identifier
zip_counts <- left_join(zip_counts, 
                        zip_pop, 
                        by = c("zip" = "ZipCode")
                        ) %>% 
  # calculate the incidence 
  mutate(
    # for each period (recent and previous)
    across(c(recent, previous), 
           # divide each variable by population (and round outcome)
           ~round(.x / Population * 10000, digits = 1), 
           # for each period create a new variable with _inc on the end
           .names = "{.col}_inc"), 
    # for each of the calculated variables (percentage and incidence)
    across(c(perc_change, recent_inc, previous_inc), 
           # fix the outliers: set missing to 0 and infity (divided by 0) to 100
           ~case_when(
             is.na(.x) ~ 0,
             .x == Inf ~ 100, 
             TRUE      ~ .x
             )
           )
    )
```

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// zip_table \\\
--------------------------------------------------------------------------------

Here we use {flextable} to produce a publication-ready table. We also demonstrate
how to colour cells based on their values, defining the cut-offs in advance using
{dplyr} case_when(). Colours are called here using HEX-codes but can also be 
referred to by name. 

For more details see: 
https://epirhandbook.com/tables-for-presentation.html
https://colorbrewer2.org/#type=sequential&scheme=Reds&n=3
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r zip_table, tab.cap = "COVID-19 new case counts by ZIP-code", tab.id = "zip_tab"}


# pick colours (uncomment next to lines)
# RColorBrewer::brewer.pal(3, "RdYlGn") %>% 
#   scales::show_col()

# choose colours to fill in cells  
row_colour <- case_when( 
  # those less than zero will be green (decreasing cases)
  zip_counts$perc_change < 0 ~ "#91CF60", 
  # over zero red (increasing)
  zip_counts$perc_change > 0 ~ "#FC8D59", 
  # missing or zero orange
  TRUE                       ~ "#FFFFBF")


zip_counts %>% 
  # keep the columns of interest and define order
  select(zip, recent, recent_inc, previous, previous_inc, perc_change) %>% 
  # initiate flextable to produce styled output table
  flextable() %>% 
  # fill in cells - choose the column and then pass our colour-scheme defined above
  bg(j = "perc_change", 
     bg = row_colour
     ) %>% 
  # add in a header for labelling counts and incidence by period 
    # note the empty columns ("") to fit to the original table headers
  add_header_row(
    values = c("", 
               str_c("Recent 14-day reporting period\n", recent_period_labels), 
               "", 
               str_c("Previous 14-day reporting period\n", previous_period_labels), 
               "", 
               "Change between reporting periods"
               )) %>% 
  # redefine column names based on original names
    # note the different syntax to dplyr::select, here it is old_name = new_name
  set_header_labels(
    zip          = "Zip Code", 
    recent       = "n", 
    recent_inc   = "Incidence", 
    previous     = "n", 
    previous_inc = "Incidence", 
    perc_change  = "%"
  ) %>% 
  # combine the headers cells for the appropriate periods 
  # (i defines rows, j defines columns)
  merge_at(i = 1, j = 2:3, part = "header") %>% 
  merge_at(i = 1, j = 4:5, part = "header") %>% 
  # move the header text to the centre
  align(align = "center", part = "header") %>% 
  # make header text bold 
  bold(part = "header") %>% 
  # make the row with totals in it bold (i.e. the last row in the dataframe)
  bold(i = nrow(zip_counts), part = "body") %>% 
  # add in footnotes for variables (referencing the header cells)
  footnote(j = c(3, 5), part = "header", ref_symbols = c("a"),
           value = as_paragraph("Incidence calculated as cases per 10,000 population by zip code")) %>% 
  footnote(j = 6, part = "header", ref_symbols = c("b"),
           value = as_paragraph("These reflect the percentage increase or decrease of new diagnoses 
                                between the 14 days preceding the past 7 days and the 14 days
                                preceding that.")) %>% 
  # make your table fit to the maximum width of the word document
  set_table_properties(layout = "autofit")

```


<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
The tag below will change the page to landscape in the word document output. 
This is part of the {officer} package - and is accompanied by a second tag below
to stop the landscape orientation. 
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

<!---BLOCK_LANDSCAPE_START--->

## Person 

<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
/// demographics_tab \\\
--------------------------------------------------------------------------------

Here we use {purrr} to iterate over demographics variables (defined in the 
vector_vars code chunk) - to produce tables of counts and percentages for cases
and deaths. 

We use {dplyr} bind_rows() and bind_cols() to combine the various smaller dataframes
of counts in to one large table. 

And then we colour in our {flextable} with different criteria for each of the 
demographic variables of interest. 

For more details see: 
https://epirhandbook.com/tables-for-presentation.html
https://epirhandbook.com/iteration-loops-and-lists.html
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->

```{r demographics_tab, tab.cap = str_c("Cumulative and recent confirmed COVID-19 case and death counts by gender, age, and race/ethnicity in Fulton County, Georgia. Past 28 day period refers to ", full_period_labels), tab.id = "demog_tab"}

# get counts tables for measures of interest 
############################################

# counts of total cases 
total_cases <- purrr::map(
  # for each variable listed
  demographic_vars,
  # create a table  
  ~tabyl(linelist, .x) %>%
    # only keep variables of interest and rename the variable column 
      # this is so that they are all the same for merging 
    select("Characteristic" = .x, n, percent)
) %>% 
  # combine rows in to one dataframe
  bind_rows()


# counts of new cases (last 28 days) 
recent_cases <- purrr::map(
  # for each variable listed
  demographic_vars, 
  # filter the linelist for dates on or after 28 days ago
  ~filter(linelist, 
          date_report >= (surveillance_date - 28)) %>% 
    # get counts based on filtered data
    tabyl(.x) %>% 
    # nb we dont keep the characteristic column because it would be duplicated
    select(n, percent)
) %>% 
  bind_rows()

# counts of total deaths 
total_deaths <- purrr::map(
  # for each variable listed
  demographic_vars, 
  # filter for those who died 
  ~filter(linelist, 
          died_covid == "Yes") %>% 
    # get counts based on filtered data 
    tabyl(.x, show_na = TRUE) %>%
    select(n, percent)
) %>% 
  bind_rows()

# counts of new deaths (last 28 days)
recent_deaths <- purrr::map(
  # for each variable listed
  demographic_vars, 
  # filter to those who died in the last 28 days
  ~filter(linelist, 
          died_covid == "Yes" & 
          date_died >= (surveillance_date - 28)) %>% 
    # get counts based on filtered data
    tabyl(.x) %>% 
    select(n, percent) %>% 
    # add in a variable column (used for colouring later) 
    mutate(variable = .x)
) %>% 
  bind_rows()


# total counts for all of the above measures (not by demographic)
overall <- linelist %>% 
  summarise(
    # add in row label 
    Characteristic = "Total",
    # counts of total cases 
    cases = n(),
    # leave all percentages empty (would just be 100)
    perc  = NA, 
    # counts of new cases (last 28 days) 
    cases_recent = sum(date_report >= (surveillance_date - 28)), 
    perc_recent  = NA, 
    # counts of total deaths 
    deaths = sum(died_covid == "Yes"), 
    perc_deaths = NA, 
    # counts of new deaths (last 28 days)
    deaths_recent = sum(died_covid == "Yes" & 
                          date_died >= (surveillance_date - 28)),
    perc_deaths_recent = NA, 
    # add in a variable column (used for colouring later) 
    variable = "Overall"
  )



# merge tables together 
#######################

# combine all the demographic tables - side by side
demographics_counts <- bind_cols(total_cases, recent_cases, total_deaths, recent_deaths) %>% 
  # mutate each of the proportion columns to be percentages
  mutate(across(contains("percent"), 
                ~round(.x * 100, digits = 1)
                )) 

# make sure names for the totals row matches the merged demographics table
names(overall) <- names(demographics_counts)

# add in the totals row at the top of the merged demographics table
demographics_counts <- bind_rows(overall, demographics_counts)



# define colour scheme 
######################

# get the column numbers than are percentages (based on the name) 
percentage_cols <- names(demographics_counts) %>% 
  str_detect("percent") %>% 
  which()

# define colour cut-offs for gender column 
gender_colours <- scales::col_bin(
  # choose colours 
  palette = c("#91CF60", "#FC8D59"), 
  # choose min and max (range)
  domain  = c(0, 100),
  # choose how to split (in this case above and below 50)
  bins    = 2
)

# define colour cut-offs for gender column 
age_colours <- scales::col_bin(
  # choose colours
  palette = c("#91CF60","#FFFFBF", "#FC8D59"),
  # choose min and max (range)
  domain  = c(0, 100), 
  # choose cut-off categories 
  bins    = c(0, 5, 20, 100)
)

# define colour cut-offs for ethnicity column 
eth_colours <- scales::col_bin(
  palette = c("#91CF60","#FFFFBF", "#FC8D59"),
  domain  = c(0, 100), 
  bins    = c(0, 10, 40, 100)
)


# create styled table  
######################

## TODO: Fix warnings and messages    

demographics_counts %>% 
  # initiate flextable to produce styled output table
  flextable(
    # retain variable column for formatting but do not display it
    col_keys = names(demographics_counts)[-10]
  ) %>% 
  # redefine column names based on original names
  set_header_labels(
    "n...2"       = "Total Confirmed Cases", 
    "percent...3" = "% of Total Cases", 
    "n...4"       = "Confirmed Cases past 28 days", 
    "percent...5" = "% of Confirmed Cases past 28 days", 
    "n...6"       = "Total Confirmed Deaths", 
    "percent...7" = "% of Total Deaths", 
    "n...8"       = "Confirmed Deaths past 28 days",
    "percent...9" = "% of Confirmed Deaths past 28 days"
  ) %>% 
  # move the header text to the centre
  align(align = "center", part = "header") %>% 
  # make header text bold 
  bold(part = "header") %>%
  # make the totals row bold (i.e. first row)
  bold(i = 1, part = "body") %>% 
  # fill in the cells
  # choose the rows with gender counts 
  bg(i = ~variable == "gender",
     # choose the columns with percentages in them 
     j = percentage_cols, 
     # fill in based on previous defined cut-offs
     bg = gender_colours) %>% 
  bg(i = ~variable == "age_group",
     j = percentage_cols, bg = age_colours) %>% 
  bg(i = ~variable == "eth_race",
     j = percentage_cols, bg = eth_colours) %>% 
  # add horizontal lines after the cells with totals and unknowns 
    # (short-cut to find row ending of each demographic variable)
  hline(i = ~Characteristic %in% c("Total", "Unknown")) %>% 
  # add in footnotes for rows counting unknowns (reference in first column)
  footnote(i = ~Characteristic == "Unknown", j = 1, part = "body", ref_symbols = c("a"),
           value = as_paragraph("Unknown includes cases not yet interviewed")) %>% 
  # add in footnote for deaths counts (ref in the header)
  footnote(i = 1, j = c(6, 8), part = "header", ref_symbols = c("b"),
           value = as_paragraph("Deaths refer to all persons who had a positive PCR test result 
                                for Covid-19 and there is evidence that COVID-19 was the cause of 
                                death or a significant contributor to their death.")) %>% 
  # make your table fit to the maximum width of the word document
  set_table_properties(layout = "autofit")

```


<!---BLOCK_LANDSCAPE_STOP--->


# Visualisation 

This is a reference to figure \@ref(fig:epicurve) below which shows xyz (TODO: say something meaningful)

```{r epicurve, fig.cap = "this is a plot", fig.id = "epicurve"}

ggplot(data = linelist,
       mapping = aes(
         x = age,
         y = days_onset_hosp))+
   geom_point()

```



 